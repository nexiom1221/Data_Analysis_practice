{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://namu.wiki/w/2020%20%EC%98%A4%EB%B2%84%EC%9B%8C%EC%B9%98%20%EB%A6%AC%EA%B7%B8/%EC%A0%95%EA%B7%9C%EC%8B%9C%EC%A6%8C%20%EA%B2%B0%EC%82%B0\n",
      "https://namu.wiki/w/%EC%B6%94%EC%A0%81%2060%EB%B6%84\n",
      "https://namu.wiki/w/%EC%86%90%ED%98%81/2020%EB%85%84\n",
      "https://namu.wiki/w/%EB%A5%98%EC%84%9D%EC%B6%98\n",
      "https://namu.wiki/w/%ED%8C%8C%EC%9D%BC:%ED%95%98%EB%A6%AC%EC%98%A4%ED%83%80%20%EB%9E%84%EB%A0%88%EC%9D%B4%EA%B0%80%EB%82%98.jpg\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# 크롤링할 사이트 주소를 정의합니다.\n",
    "source_url = \"https://namu.wiki/RecentChanges\"\n",
    "\n",
    "# 사이트의 html 구조에 기반하여 크롤링을 수행합니다.\n",
    "req = requests.get(source_url)\n",
    "html = req.content\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "contents_table = soup.find(name=\"table\")\n",
    "table_body = contents_table.find(name=\"tbody\")\n",
    "table_rows = table_body.find_all(name=\"tr\")\n",
    "# a태그의 href 속성을 리스트로 추출하여, 크롤링 할 페이지 리스트를 생성합니다.\n",
    "page_url_base = \"https://namu.wiki\"\n",
    "page_urls = []\n",
    "for index in range(0, len(table_rows)):\n",
    "    first_td = table_rows[index].find_all('td')[0]\n",
    "    td_url = first_td.find_all('a')\n",
    "    if len(td_url) > 0:\n",
    "        page_url = page_url_base + td_url[0].get('href')\n",
    "        if 'png' not in page_url:\n",
    "            page_urls.append(page_url)\n",
    "\n",
    "# 중복 url을 제거합니다.\n",
    "page_urls = list(set(page_urls))\n",
    "for page in page_urls[:5]:\n",
    "    print(page)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020 SKT 5GX JUMP 카트라이더 리그 시즌2 \n",
      "\n",
      "\n",
      "카트라이더 리그OGN\n",
      "\n",
      "\n",
      "역대 카트라이더 리그 일람2020 SKT JUMP 카트라이더 리그 시즌1→2020 SKT 5GX JUMP 카트라이더 리그 시즌2 →넥슨 2021 카트라이더 리그 시즌1역대 카트라이더 리그 [ 펼치기 · 접기 ] OGNCokePlay 1차(2005)올림푸스 2차(2005)스프리스 3차(2006)넥슨 4차(2006)개인전SK1682 5차(2007)GomTV 6차(2007)초코송이 7차(2007)Afreeca 8차(2008)버디버디 9차(2008)버디버디 10차(2008)넥슨 11차(2010)넥슨 12차(2010)넥슨 13차 (2011)넥슨 14차(2011)넥슨 15차(2012)넥슨 팀스피릿(2011)넥슨 16차(2012)넥슨 17차(2012)팀전SPOTVGAMES넥슨 시즌 제로(2014)넥슨 배틀 로얄(2014)넥슨 에볼루션(2015)넥슨 버닝 타임(2016)넥슨 듀얼 레이스(2016)넥슨 듀얼 레이스 2(2017)넥슨 듀얼 레이스 3(2018)넥슨 듀얼 레이스 X(2018)개인전팀전넥슨  2019 시즌 1(2019)KT 5G 멀티뷰  2019 시즌 2(2019)SKT JUMP  2020 시즌 1(2020)OGNSKT 5GX JUMP  2020 시즌 2(2020)기타역대 카트라이더 리그 일람 · 카트라이더 리그 스토브리그 · 비공식리그 OGNCokePlay 1차(2005)올림푸스 2차(2005)스프리스 3차(2006)넥슨 4차(2006)개인전SK1682 5차(2007)GomTV 6차(2007)초코송이 7차(2007)Afreeca 8차(2008)버디버디 9차(2008)버디버디 10차(2008)넥슨 11차(2010)넥슨 12차(2010)넥슨 13차 (2011)넥슨 14차(2011)넥슨 15차(2012)넥슨 팀스피릿(2011)넥슨 16차(2012)넥슨 17차(2012)팀전SPOTVGAMES넥슨 시즌 제로(2014)넥슨 배틀 로얄(2014)넥슨 에볼루션(2015)넥슨 버닝 타임(2016)넥슨 듀얼 레이스(2016)넥슨 듀얼 레이스 2(2017)넥슨 듀얼 레이스 3(2018)넥슨 듀얼 레이스 X(2018)개인전팀전넥슨  2019 시즌 1(2019)KT 5G 멀티뷰  2019 시즌 2(2019)SKT JUMP  2020 시즌 1(2020)OGNSKT 5GX JUMP  2020 시즌 2(2020)기타역대 카트라이더 리그 일람 · 카트라이더 리그 스토브리그 · 비공식리그2020 SKT 5GX JUMP 카트라이더 리그 시즌2 대회 기간2020년 8월 22일 ~ 11월 7일주최/주관경기장서울 OGN e스타디움스폰서중계  [ 펼치기 · 접기 ]중계 플랫폼TV  온라인       중계진캐스터 성승헌해설자 정준, 김대겸인터뷰 아나운서최시은중계 플랫폼TV  온라인       중계진캐스터 성승헌해설자 정준, 김대겸인터뷰 아나운서최시은일정  [ 펼치기 · 접기 ]개인전32강 8월 22일 ~ 9월 19일16강 9월 23일 ~ 10월 24일팀전8강 풀리그 8월 22일 ~ 10월 14일포스트 시즌 10월 17일 ~ 11월 4일결승전팀전 / 개인전 11월 7일경기장 미정개인전32강 8월 22일 ~ 9월 19일16강 9월 23일 ~ 10월 24일팀전8강 풀리그 8월 22일 ~ 10월 14일포스트 시즌 10월 17일 ~ 11월 4일결승전팀전 / 개인전 11월 7일경기장 미정결과  [ 펼치기 · 접기 ]우승 팀전 개인전 준우승팀전 개인전 우승 팀전 개인전 준우승팀전 개인전 1. 개요2. 시즌 전 스토브리그3. 참가 팀4. 상금5. 경기 일정5.1. 온라인 예선6. 규정7. 출전 선수7.1. 팀전7.2. 개인전8. 경기 진행9. 결과9.1. 팀전9.2. 개인전10. 트랙별 베스트 레코드10.1. 팀전10.2. 개인전11. 논란 및 사건사고12. 여담팀 프로모 영상예선 통과 4팀샌드박스 게이밍One For All, All For One하나는 모두를 위해, 모두는 하나를 위해넥슨이 주최하는 29번째 카트라이더 리그.     자세한 내용은 카트라이더 리그 스토브리그/2020 시즌 2 문서를의 번째 문단을의  부분을 참고하십시오.   2020 SKT 5GX JUMP 카트라이더 리그 시즌2참가팀    2020 SKT 5GX JUMP 카트라이더 리그 시즌2참가팀 Hanwha Life EsportsSeongnam ROXAfreeca FreecsSANDBOX GamingGC Busan E-STATSSGA eSPORTSSTARLIGHTMOTOHanwha Life EsportsSeongnam ROXAfreeca FreecsSANDBOX GamingGC Busan E-STATSSGA eSPORTSSTARLIGHTMOTO총 상금9,000만원 개인전  우승 500만원 준우승 300만원 3위 100만원 팀전  우승 4,000만원 준우승 2,000만원 3위 800만원 4위 500만원5위~8위200만원전 시즌인 2020 SKT JUMP 카트라이더 리그 시즌1과 변동 사항 없이 상금 내역은 똑같다.본선 일정 (팀전 / 개인전)날짜팀전개인전8월 22일 (토)8강 풀리그 1경기8강 풀리그 2경기32강 A조8월 26일 (수)8강 풀리그 3경기8강 풀리그 4경기8월 29일 (토)8강 풀리그 5경기8강 풀리그 6경기32강 B조9월 2일 (수)8강 풀리그 7경기8강 풀리그 8경기9월 5일 (토)8강 풀리그 9경기8강 풀리그 10경기32강 C조9월 9일 (수)8강 풀리그 11경기8강 풀리그 12경기9월 12일 (토)8강 풀리그 13경기8강 풀리그 14경기32강 D조9월 16일 (수)8강 풀리그 15경기8강 풀리그 16경기9월 19일 (토)8강 풀리그 17경기8강 풀리그 18경기32강 패자부활전9월 23일 (수)8강 풀리그 19경기8강 풀리그 20경기16강 1경기9월 26일 (토)8강 풀리그 21경기8강 풀리그 22경기16강 2경기9월 30일 (수)추석 연휴10월 3일(토)10월 7일 (수)8강 풀리그 23경기8강 풀리그 24경기10월 10일 (토)8강 풀리그 25경기8강 풀리그 26경기16강 승자전10월 14일 (수)8강 풀리그 27경기8강 풀리그 28경기10월 17일 (토)와일드카드전(5위 vs 4위)16강 패자전10월 21일 (수)준플레이오프(와일드카드전 승자 vs 3위)10월 24일 (토)결승 진출전(1위 vs 2위)16강 최종전11월 4일 (수)플레이오프(준플레이오프 승자 vs 결승 진출전 패자)11월 7일 (토)결승전지난 시즌에서는 팀전 8강 풀리그 이후 또다시 4강 풀리그를 거쳐 플레이오프를 치루었다. 하지만 이번 시즌에는 4강 풀리그를 폐지했고 McIntyre System을 변형한 방식을 도입했다. 또한, 5등은 탈락한 팀들과 상금이 동일한데 이는 와일드카드전의 취지를 잘 살린 것으로 평가된다. 4팀이 아닌 5팀이 진출하기 때문에 기존의 4강 구도 밖의 팀들에게도 동기부여가 충분히 될 수 있다는 것도 긍정적이다.   자세한 내용은 2020 SKT 5GX JUMP 카트라이더 리그 시즌2/온라인 예선 문서를의 번째 문단을의  부분을 참고하십시오.   자세한 내용은 2020 SKT 5GX JUMP 카트라이더 리그 시즌2/규정 문서를의 번째 문단을의  부분을 참고하십시오.2020 SKT JUMP 카트라이더 리그 시즌1 결승 진출 팀인 한화생명e스포츠, 성남 ROX가 특별 시드를 받아 오프라인 예선이 면제되고 본선으로 직행했다.[1] 이후 카트라이더 리그 시즌 2 팀 지원 프로젝트 평가를 통해 Afreeca Freecs, SANDBOX Gaming이 추가로 본선 시드를 획득했다.선수 명 아래의 문구는 해당 선수가 팀전에서 거둔 우승 횟수 혹은 최고 성적을 의미한다.한화생명e스포츠ITEM ACESWEEPERSPEED ACE HYBRIDRUNNER강석인★★★박도현★문호준★★★최영훈★★★★배성빈★팀전 디펜딩 챔피언으로서 방어전에 나선다. 3년 동안 2번의 팀전 우승을 합작한 문호준-최영훈-강석인 조합이 다시 꾸려졌고, 타 팀에 비해 변화가 적은 편이라 팀합에서도 유리하다는 평이다. 또한 문호준의 팀전 올인으로, 꾸준히 성장 중인 배성빈-박도현의 포텐셜을 어디까지 더 끌어낼지도 궁금해지게 되는 팀.성남 ROXSWEEPERMIDDLESPEED ACERUNNERITEM ACE 송용준준우승한승철★이재혁준우승신종민5위사상훈준우승전 시즌 준우승 후 김응태가 군입대로 은퇴를 선언하며 신종민을 영입했다. 기존의 ROX는 오랜 기간 합을 맞춘 끈끈함을 장점으로 하는 팀이었지만, 새로운 멤버와 새로운 팀워크를 만들어야 한다는 점은 ROX에게 큰 과제가 될 것이다. 아이템전은 전력을 유지했지만 스피드전에서는 꽤나 영향이 있을 것으로 보이는데 개인전의 퍼포먼스와는 다르게 팀전만 하면 팀킬이 빈번하기로 유명한 신종민이 팀의 케어를 받고 어디까지 안정성을 끌어올릴 수 있을지가 포인트.Afreeca FreecsITEM ACEHYBRIDSPEED ACE RUNNERSWEEPER이은택★★★★★홍승민3위유영혁★★★★★김기수3위최윤서3위전 시즌 가장 큰 로스터 관련 논란의 중심이었던 팀인 프릭스가 이번 시즌도 가장 큰 로스터 변경을 감행하고 이미지 체인지에 도전한다. 스피드전에서는 기존의 유영혁-최윤서에 김기수가 영입되며 상당히 밸런스 잡힌 구성이라는 평이 많지만, 아이템전은 사실상 이은택의 능력치에 모든걸 건 수준이라는 평가다. 그 이은택마저도 이전 시즌 트랙 스코어로는 이은택답지 않은 부진으로 자존심을 구겼고 유영혁은 여전히 아이템전 실력이 경험에 비해 매우 저조한 것, 김기수는 최윤서와의 경쟁에서 밀려났는데 최윤서마저 아이템전에 상당한 부담을 안고 있다. 홍승민 또한 기존 아이템전에 자신있어하는 모습과 다르게 부진하고 있는 것으로 보여, 이은택의 어깨가 무겁다. 2연속 3위 입상의 프릭스가 이번 시즌에는 더 높은곳으로 올라갈 수 있을지 관심이 모이고 있다.SANDBOX GamingRUNNERHYBRIDSPEED ACE SWEEPER정승하3위김승태★★★★박인수★★박현수★충격의 4강 탈락 이후, 5인 체제로 변경하는 것이 아닌가 하는 예상이 지배적이었으나, 유창현의 자리에 정승하가 들어오며 4인 체제를 유지했다. 리그 최강급의 하이브리드였던 유창현에 비해 아이템전은 다소 밀리는 감이 있으나, 스피드전에서는 여전히 강한 면모를 보일 것으로 예상된다. 단, 전 시즌 박인수의 에결 3연패라는 굴욕은 여전히 뼈아픈 상황이며, 박인수의 1대1 전략이 상당 부분 연구되고 파훼되어 압도적인 경기를 수행하기에 다소 어려움이 생겼다. 하지만 샌드박스의 팀워크는 여전히 건재하며, 언제 다시 우승해도 이상하지 않은 팀이라는 평이 많다.GC Busan E-STATSHYBRIDRUNNER SWEEPERSPEED ACEITEM ACE김지민5위전대웅★★임재원4위노준현첫 출전유관영3위임재원이 맨땅에 헤딩을 해서 얻어낸 새로운 프로팀. 스토브리그 과정에서 아마추어 팀에 대한 민폐 등의 논란이 있기는 했으나, 예선에서 압도적인 힘을 보여주며[2] 당당하게 본선에 진출했다. 카트라이더 리그 사상 최초로 5인팀 체제 모든 선수가 개인전 본선에 진출할 정도로 스피드전에서는 분명 강점이 뚜렷하지만, 아직 대부분 선수가 리그 신예급이라는 것이 걸림돌. 카멜롯을 제외한 모든 트랙이 구맵으로 뽑힌 이번 시즌에서는 전대웅의 존재만으로 일단 에결로 끌고 가면 기대할 만하다. 기존 강팀들에 대해 어느 정도까지 상대할 수 있을지에 따라 5강 체제가 확립될 수도 있는 만큼 선전이 필요한 팀.SGAe스포츠HYBRIDSWEEPERSPEED ACE ITEM ACERUNNER장건5위이현진8위안혁진4위노창현8위홍희권5위누구도 섣불리 예상하지 못한 프로팀.[3] 예선에서는 충분한 강함과 반전을 보여주었으나 문제는 본선부터다. 개인전 본선에 단 한 명의 선수도 올리지 못한 유일한 프로팀이라는 불명예까지 리그가 시작하기도 전부터 끌어안고 가게 되었다. 기존 리그에서 나름 선전한 홍희권, 장건을 영입하여 상황은 그나마 나아졌긴 했지만, 1GO에도 밀린다는 평을 들을 정도로 4강권 팀에 비해 전력은 비할 바가 못된다는 평이 지배적이다. 게다가 다른 팀과는 달리 확실한 에결 카드가 없다는 것도 문제.[4] 하지만 스피드전에서 좋은 모습을 보여준다면 의외의 복병이 될 가능성도 충분하다.STARLIGHTMIDDLERUNNERSPEED ACE ITEM ACESWEEPER최민석첫 출전유민선첫 출전김정제3위정승민3위정유민첫 출전듀얼 레이스 시절 신인으로서 상당한 임팩트를 남겼던 김정제를 주축으로 만들어진 신인 위주의 아마추어 팀. 8강권 프로팀에 밀리지 않는 전력을 가졌다는 평이 많으며, Oz-FANTASTICK의 창단 감독인 김현민 감독이 복귀한 팀이다. 오랜만에 출전한 군필 라이더 김정제의 폼, 아이템 천상계 3인방 다음급이라는 평가를 받는 정승민이 2년만에 맞추는 시너지, 그리고 신인 선수들의 활약을 기대해 볼 수 있는 팀이다.[5]MOTOMIDDLESWEEPERRUNNER SPEED ACEITEM ACE박민호첫 출전이은서첫 출전박대한첫 출전김현민첫 출전김택진7위기존 리그 시청자들도 이름을 잘 모를 법한 선수들이 모인 완전한 아마추어 팀. 대부분 선수들이 리그 경험이 없다는 것이 강점이자 약점이 될 팀이다. 데이터도 전적도 미지수인 팀이기에 과연 본선에서 어느정도의 성과를 낼 수 있을지, 새롭게 리그에 도전하는 신예 선수들의 노력과 숨은 실력에 주목해 보자. 워낙 전력이 약하기 때문에 1승만 해도 이번 시즌은 성공이라는 평이 다수. 카갤 등에서는 세트 스코어 -14, 트랙 스코어 -42가 최초로 나오는 것 아니냐는 말도 나오고 있다(...) 굳이 비교하자면 듀얼 레이스 3 때의 아옥스틱 팀이나 2019 시즌 1 때의 프로페셔널 팀과 비슷한 수준.문호준의 개인전 은퇴와 유창현의 무기한 휴식, 오프라인 예선에서 실격된 여러 선수들 등 여러가지 요소가 겹치면서 개인전에 첫 출전하는 '꿀벌즈' 그룹이 9명으로 전 시즌에 비해 매우 많아졌다.A조선수전대웅김기수전진우최윤서송용준이은서김정제최영훈최고 성적[B]준우승7위첫 출전13위5위첫 출전4위10위B조선수박인수노준현유관영신종민한승철장채민[실격]임재원우성민최고 성적[B]준우승첫 출전첫 출전7위15위첫 출전12위20위C조선수유영혁김지민김현민김주영박도현최민석최태원정승하최고 성적[B]★x218위31위22위준우승12위첫 출전4위D조선수이재혁권승주정승민[10]배성빈박현수김승래이정우정유민최고 성적[B]★x1첫 출전첫 출전3위11위7위첫 출전23위온라인 예선개인전32강16강결승전팀전8강 풀리그포스트시즌결승전 트랙기록 경기팀선수카트바디카멜롯 외곽 순찰로1:??:?????경기?????? X님프 바다신전의 비밀2:??:????????? X차이나 골목길 대질주2:??:????????? X황금문명 비밀장치의 위협1:??:????????? X문힐시티 숨겨진 지하터널1:??:????????? X동화 잠자는 숲속의 거인1:??:????????? X팩토리 두개의 공장1:??:????????? X빌리지 지우펀1:??:????????? X사막 놀라운 공룡 유적지1:??:????????? X포레스트 오싹한 공중다리2:??:????????? X 트랙기록 경기선수카트바디카멜롯 펜드래건 캐슬1:??:???어비스 숨겨진 바닷길1:??:???대저택 은밀한 지하실1:??:???황금문명 오르에트 황금 좌표1:??:???동화 이상한 나라의 문2:??:???[리버스] 해적 로비 절벽의 전투1:??:???광산 위험한 제련소2:??:???공동묘지 해골성 대탐험1:??:???아이스 부서진 빙산1:??:???아이스 아찔한 헬기 점프2:??:???카트라이더 16주년 방구석 간담회에서 조재윤이 이번 리그에서 우승한 선수/팀에게 마지막 맵을 카멜롯 테마로 선택한다면 그 트랙에 개인전/팀전 우승자들의 동상을 세워주겠다고 했다. 이 사실은 이후 개발자의 편지를 통해 확인되었다.2020년 8월 중순에 COVID-19가 전 세계적으로 악화되고, 국내 신규 감염자가 증가한 추세다 보니 선수들의 건강을 걱정하는 반응이 많다.\n"
     ]
    }
   ],
   "source": [
    "# 크롤링한 데이터를 데이터 프레임으로 만들기 위해 준비합니다.\n",
    "columns = ['title', 'category', 'content_text']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# 각 페이지별 '제목', '카테고리', '본문' 정보를 데이터 프레임으로 만듭니다.\n",
    "for page_url in page_urls:\n",
    "\n",
    "    # 사이트의 html 구조에 기반하여 크롤링을 수행합니다.\n",
    "    req = requests.get(page_url)\n",
    "    html = req.content\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    contents_table = soup.find(name=\"article\")\n",
    "    title = contents_table.find_all('h1')[0]\n",
    "    category = contents_table.find_all('ul')[0]\n",
    "    content_paragraphs = contents_table.find_all(name=\"div\", attrs={\"class\":\"wiki-paragraph\"})\n",
    "    content_corpus_list = []\n",
    "    \n",
    "for paragraphs in content_paragraphs:\n",
    "    content_corpus_list.append(paragraphs.text)\n",
    "content_corpus = \"\".join(content_corpus_list)\n",
    "\n",
    "print(title.text)\n",
    "print(\"\\n\")\n",
    "print(category.text)\n",
    "print(\"\\n\")\n",
    "print(content_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-a3eff3ec6f99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mcontents_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"table\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"class\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"table-hover\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mtable_body\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontents_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"tbody\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mtable_rows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtable_body\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"tr\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "source_url = \"https://namu.wiki/RecentChanges\"\n",
    "\n",
    "req = requests.get(source_url)\n",
    "html = req.content\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "contents_table = soup.find(name=\"table\", attrs={\"class\":\"wiki-paragraph\"})\n",
    "table_body = contents_table.find(name=\"tbody\")\n",
    "table_rows = table_body.find_all(name=\"tr\")\n",
    "\n",
    "# a 태그의 href 속성을 리스트로 추출, 크롤링 페이지 리스트 생성\n",
    "page_url_base = \"https://namu.wiki\"\n",
    "page_urls = []\n",
    "for index in range(0, len(table_rows)):\n",
    "    first_td = table_rows[index].find_all('td')[0]\n",
    "    td_url = first_td.find_all('a')\n",
    "    if len(td_url) >0 :\n",
    "        page_url = page_url_base + td_url[0].get('href')\n",
    "        page_urls.append(page_url)\n",
    "\n",
    "# 중복 url 제거\n",
    "page_urls = list(set(page_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
